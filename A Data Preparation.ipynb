{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 322](https://github.com/GonzagaCPSC322) Data Science Algorithms\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "\n",
    "# Data Preparation\n",
    "What are our learning objectives for this lesson?\n",
    "* Learn about the steps involved in data preprocessing\n",
    "* Learn about different attribute types\n",
    "* Summarize data with simple statistics\n",
    "* Clean data by filling missing values\n",
    "\n",
    "Content used in this lesson is based upon information in the following sources:\n",
    "* Dr. Shawn Bowers' Data Mining notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-up Task(s)\n",
    "* Create a new directory called DataPreparationFun and a main.py in this directory\n",
    "    * In main.py, write a function called `get_column(table, header, col_name)` that returns a column in the table\n",
    "        * Find the index of the column by looking up `col_name`'s position in `header`\n",
    "        * Ignore \"NA\" values\n",
    "    * Test your function by getting the \"MSRP\" column from the following table:\n",
    "\n",
    "```\n",
    "header = [\"CarName\", \"ModelYear\", \"MSRP\"]\n",
    "msrp_table = [[\"ford pinto\", 75, 2769],\n",
    "              [\"toyota corolla\", 75, 2711],\n",
    "              [\"ford pinto\", 76, 3025],\n",
    "              [\"toyota corolla\", 77, 2789]]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Today\n",
    "* Announcements\n",
    "    * RQ3 is due Monday night\n",
    "    * Nice job on getting PA1 done. Let's see the solutions to the data science questions :)\n",
    "    * Work on PA2\n",
    "        * VS Code test discovery demo again? \n",
    "        * Questions?\n",
    "* Table join traces\n",
    "* Start DataPreparationFun\n",
    "* Last ~15 mins of class: IQ2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "Data analysts spend a surprising amount of time preparing data for analysis. In fact, a survey was conducted found that cleaning big data is the most time-consuming and least enjoyable task data scientists do!\n",
    "<img src=\"https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg\" width=\"700\">\n",
    "(image from [https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg](https://thumbor.forbes.com/thumbor/960x0/https%3A%2F%2Fblogs-images.forbes.com%2Fgilpress%2Ffiles%2F2016%2F03%2FTime-1200x511.jpg))\n",
    "\n",
    "The goal of data preprocessing is to produce high-quality data to improve mining results and efficiency\n",
    "\n",
    "At a high level, data preprocessing includes the following steps (these steps are done in any order and often multiple times):\n",
    "1. Data Exploration (basic understanding of meaning, attributes, values, issues)\n",
    "2. Data Reduction (reduce size via aggregation, redundant features, etc.)\n",
    "3. Data Integration (merge/combine multiple datasets)\n",
    "4. Data Cleaning (remove noise and inconsistencies)\n",
    "5. Data Transformation (normalize/scale, etc.)\n",
    "\n",
    "It is important for data mining that your process is transparent and repeatable:\n",
    "* Can repeat \"experiment\" and get the same result\n",
    "* No \"magic\" steps\n",
    "\n",
    "It is important, however, to write down steps (log):\n",
    "* Ideally, someone should be able to take your data, program, and description of steps, rerun everything, and get the same results!\n",
    "\n",
    "## Data Exploration\n",
    "Get to know your data first by exploring it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall: Tabular Data\n",
    "Our focus is “Tabular” Data ... aka Relational or Structured\n",
    "* Data is organized into tables (rows and columns)\n",
    "\n",
    "Age |Gender |Impressions |Clicks |SignedIn\n",
    "-|-|-|-|-|\n",
    "59 |1 |4 |0 |1\n",
    "19 |0 |5 |0 |1\n",
    "44 |1 |5 |0 |1\n",
    "28 |1 |4 |0 |1\n",
    "61 |1 |10 |1 |1\n",
    "0 |0 |3 |1 |0\n",
    "\n",
    "* Each row is an \"instance\"\n",
    "    * aka \"example\", \"record\", or \"object\"\n",
    "* Each column is an “attribute” (of the instance)\n",
    "    * aka \"variables\" or \"fields\"\n",
    "* A \"dataset\" is a (sample) set of instances\n",
    "    * from the \"universe of objects\" (universe of instances)\n",
    "\n",
    "This is a sample of (simulated) daily website click stream data (Example from \"Doing Data Science\", Schutt and O’Neil)\n",
    "* Each row contains attribute values for one user\n",
    "* User’s age, gender (0=female, 1=male), ads shown, ads clicked, and if\n",
    "logged in (0=no, 1=yes)\n",
    "\n",
    "### Recall: Keys\n",
    "An (optional) \"key\" is one or more attributes with unique values\n",
    "* E.g. The values that uniquely identify instances in a table\n",
    "\n",
    "For example:\n",
    "\n",
    "UserId |Age |Gender |Impressions |Clicks |SignedIn\n",
    "-|-|-|-|-|-|\n",
    "20 |59 |1 |4 |0 |1\n",
    "15 |19 |0 |5 |0 |1\n",
    "31 |44 |1 |5 |0 |1\n",
    "71 |28 |1 |4 |0 |1\n",
    "51 |61 |1 |10 |1 |1\n",
    "60 |0 |0 |3 |1 |0\n",
    "\n",
    "* here, each UserId value identifies the user\n",
    "\n",
    "Q: What was the key w/out UserId? ... A: None (row id)\n",
    "\n",
    "### More on Keys: Multiple Attribute Keys (AKA Composite Keys)\n",
    "Composite key (from [GeeksforGeeks](https://www.geeksforgeeks.org/composite-key-in-sql/)): A composite key is made by the combination of two or more columns in a table that can be used to uniquely identify each row in the table when the columns are combined uniqueness of a row is guaranteed, but when it is taken individually it does not guarantee uniqueness, or it can also be understood as a primary key made by the combination of two or more attributes to uniquely identify every row in a table. \n",
    "\n",
    "CarName |ModelYear |MSRP\n",
    "-|-|-\n",
    "ford pinto |75 |2769\n",
    "toyota corolla |75 |2711\n",
    "ford pinto |76 |3025\n",
    "toyota corolla |76 |2789\n",
    "... |... |...\n",
    "\n",
    "Q: What are the key attributes? ... A: {CarName, ModelYear}\n",
    "\n",
    "Q: Why not just CarName? ... A: Values not unique across rows\n",
    "\n",
    "### More on Keys: Foreign Keys\n",
    "A \"Foreign Key\" is a reference to instances, typically to instances in another table (but could be to the same table)\n",
    "\n",
    "For example:\n",
    "\n",
    "SaleId |EmployeeId |CarName |ModelYear |Amt\n",
    "-|-|-|-|-\n",
    "555 |12 |ford pinto |75 |3076\n",
    "556 |12 |toyota corolla |75 |2611\n",
    "998 |13 |toyota corolla |75 |2800\n",
    "999 |12 |toyota corolla |76 |2989\n",
    "... |... |... |... |...\n",
    "\n",
    "Q: What is the key?\n",
    "* {SaleId}\n",
    "\n",
    "Q: What are the foreign keys (references)?\n",
    "* {CarName, ModelYear}\n",
    "* {EmployeeId} for information about the salesperson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join\n",
    "We can “Join” (combine) two tables on any attributes\n",
    "* but typically on keys/foreign keys\n",
    "\n",
    "SaleId |EmployeeId |CarName |ModelYear |Amt\n",
    "-|-|-|-|-\n",
    "555 |12 |ford pinto |75 |3076\n",
    "556 |12 |toyota corolla |75 |2611\n",
    "998 |13 |toyota corolla |75 |2800\n",
    "999 |12 |toyota corolla |76 |2989\n",
    "... |... |... |... |...\n",
    "\n",
    "CarName |ModelYear |MSRP\n",
    "-|-|-\n",
    "ford pinto |75 |2769\n",
    "toyota corolla |75 |2711\n",
    "ford pinto |76 |3025\n",
    "toyota corolla |77 |2789\n",
    "... |... |...\n",
    "\n",
    "\n",
    "Two main ways to join tables:\n",
    "* Inner join: only matches are returned\n",
    "* Full outer join: both matches and non-matches (by “null” padding) are returned\n",
    "    * Where a “null” value means a missing value\n",
    "    * We’ll use “NA” to mean null\n",
    "\n",
    "SaleId |EmployeeId |CarName |ModelYear |Amt\n",
    "-|-|-|-|-\n",
    "555 |12 |ford pinto |75 |3076\n",
    "556 |12 |toyota corolla |75 |2611\n",
    "998 |13 |toyota corolla |75 |2800\n",
    "999 |12 |toyota corolla |76 |2989\n",
    "\n",
    "CarName |ModelYear |MSRP\n",
    "-|-|-\n",
    "ford pinto |75 |2769\n",
    "toyota corolla |75 |2711\n",
    "ford pinto |76 |3025\n",
    "toyota corolla |77 |2789\n",
    "\n",
    "Inner join result:\n",
    "\n",
    "SaleId |EmployeeId |CarName |ModelYear |Amt |MSRP\n",
    "-|-|-|-|-|-\n",
    "555 |12 |ford pinto |75 |3076 |2769\n",
    "556 |12 |toyota corolla |75 |2611 |2711\n",
    "998 |13 |toyota corolla |75 |2800 |2711\n",
    "\n",
    "Full outer join result:\n",
    "\n",
    "SaleId |EmployeeId |CarName |ModelYear |Amt |MSRP\n",
    "-|-|-|-|-|-\n",
    "555 |12 |ford pinto |75 |3076 |2769\n",
    "556 |12 |toyota corolla |75 |2611 |2711\n",
    "998 |13 |toyota corolla |75 |2800 |2711\n",
    "999 |12 |toyota corolla |76 |2989 |NA\n",
    "NA |NA |ford pinto |76 |NA |3025\n",
    "NA |NA |toyota corolla |77 |NA |2789\n",
    "\n",
    "* left outer join = join + rows in first table w/out matches in second\n",
    "* right outer join = join + rows in second table w/out matches in first\n",
    "\n",
    "Q: How would we join these two tables? What is different?\n",
    "\n",
    "MPG |Cyls |Displacement | Hrspwr | Wght| Accel |ModelYear| Origin |CarName\n",
    "-|-|-|-|-|-|-|-|-\n",
    "23.0 | 4 | 140.0 | 83.0 | 2639 | 17.0 | 75 | 1 | ford pinto\n",
    "29.0 | 4 | 97.0 | 75.0 | 2171 | 16.0 | 75 | 3 | toyota corolla\n",
    "... |... |... |... |... |... |... |... |...\n",
    "\n",
    "CarName|ModelYear |MSRP\n",
    "-|-|-\n",
    "ford pinto |75 |2769\n",
    "toyota corolla |75 |2711\n",
    "... |... |...\n",
    "\n",
    "* Join both on the composite key {CarName, ModelYear}\n",
    "\n",
    "### Join Practice Problem\n",
    "Perform both an inner and an outer join on the following two tables on composite key {CarName, ModelYear}\n",
    "\n",
    "ModelYear |EmployeeId |SaleId |CarName |Amt\n",
    "-|-|-|-|-\n",
    "75.0| 12.0|   555.0|      ford pinto|  3076.0\n",
    "79.0| 12.0 |  556.0|    toyota truck|  2989.0\n",
    "75.0| 12.0  | 557.0|  toyota corolla|  2611.0\n",
    "75.0| 13.0   |996.0|  toyota corolla|  2800.0\n",
    "76.0| 12.0   |997.0|  toyota corolla|  2989.0\n",
    "74.0| 12.0   |998.0|      ford pinto|  2989.0\n",
    "77.0| 12.0   |999.0|    ford mustang|  2989.0\n",
    "\n",
    "CarName |MSRP |ModelYear \n",
    "-|-|-\n",
    "honda accord  |2789.0       |75.0\n",
    "ford pinto  |2769.0       |75.0\n",
    "toyota corolla  |2711.0       |75.0\n",
    "ford pinto  |3025.0       |76.0\n",
    "toyota corolla  |2789.0       |77.0\n",
    "range rover  |3333.0       |70.0\n",
    "ford pinto  |2567.0       |73.0\n",
    "toyota corolla  |2999.0       |75.0\n",
    "\n",
    "<!-- Inner join solution:\n",
    "\n",
    "ModelYear |EmployeeId |SaleId         |CarName     |Amt    |MSRP\n",
    "-|-|-|-|-|-\n",
    "75.0       |12.0  |555.0      |ford pinto  |3076.0  |2769.0\n",
    "75.0       |12.0  |557.0  |toyota corolla  |2611.0  |2711.0\n",
    "75.0       |12.0  |557.0  |toyota corolla  |2611.0  |2999.0\n",
    "75.0       |13.0  |996.0  |toyota corolla  |2800.0  |2711.0\n",
    "75.0       |13.0  |996.0  |toyota corolla  |2800.0  |2999.0\n",
    "\n",
    "Full outer join solution:\n",
    "\n",
    "ModelYear |EmployeeId |SaleId         |CarName     |Amt    |MSRP\n",
    "-|-|-|-|-|-\n",
    "75.0       |12.0  |555.0      |ford pinto  |3076.0  |2769.0\n",
    "79.0       |12.0  |556.0    |toyota truck  |2989.0      |NA\n",
    "75.0       |12.0  |557.0  |toyota corolla  |2611.0  |2711.0\n",
    "75.0       |12.0  |557.0  |toyota corolla  |2611.0  |2999.0\n",
    "75.0       |13.0  |996.0  |toyota corolla  |2800.0  |2711.0\n",
    "75.0       |13.0  |996.0  |toyota corolla  |2800.0  |2999.0\n",
    "76.0       |12.0  |997.0  |toyota corolla  |2989.0      |NA\n",
    "74.0       |12.0  |998.0      |ford pinto  |2989.0      |NA\n",
    "77.0       |12.0  |999.0    |ford mustang  |2989.0      |NA\n",
    "75.0         |NA     |NA    |honda accord      |NA  |2789.0\n",
    "76.0         |NA     |NA      |ford pinto      |NA  |3025.0\n",
    "77.0         |NA     |NA  |toyota corolla      |NA  |2789.0\n",
    "70.0         |NA     |NA     |range rover      |NA  |3333.0\n",
    "73.0         |NA     |NA      |ford pinto      |NA  |2567.0 -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on Attributes\n",
    "Different aspects of attributes (variables)\n",
    "* Data (storage) type - e.g., int versus float versus string\n",
    "* Measurement scales - are values discrete or continuous\n",
    "* Semantic type – what the values represent (e.g., colors, ages)\n",
    "\n",
    "### Measurement Scales\n",
    "1. Nominal\n",
    "    * Discrete values without inherent order\n",
    "    * E.g., colors (red, blue, green), identifiers, occupation, gender\n",
    "    * Often ints or strings (but could be any data type)\n",
    "2. Ordinal\n",
    "    * Discrete values with inherent order\n",
    "    * E.g., t-shirt size (s, m, l, xl), grades (A+, A-, B+, ...)\n",
    "    * No guarantee that the difference between values is same\n",
    "    * Often ints or strings (but could be any data type)\n",
    "3. Interval\n",
    "    * Values measured on a scale of equal-sized widths\n",
    "    * Unlike ordinal, can compare and quantify difference between values\n",
    "    * No inherent zero point (i.e., absence)\n",
    "    * Temperature (Celsius, Fahrenheit) is an example\n",
    "4. Ratio\n",
    "    * Interval values with an inherent zero point\n",
    "    * Temperature in Kelvin is an example\n",
    "    * Also counts of things (where 0 means not present)\n",
    "    \n",
    "### Categorical vs Continuous\n",
    "* Categorical roughly means the nominal and ordinal values\n",
    "* Continuous roughly means the rest (interval, ratio) ... aka \"numerical\"\n",
    "* For many algorithms/approaches, this is enough detail\n",
    "\n",
    "### Labeled vs Unlabeled Data\n",
    "* Labeled data implies an attribute that classifies instances (e.g., mpg)\n",
    "    * Goal is typically to predict the class for new instances\n",
    "    * This is called \"Supervised Learning\"\n",
    "* Unlabeled means there isn't such an attribute (for mining purposes)\n",
    "    * Can still find patterns, associations, etc.\n",
    "    * Generally referred to as \"Unsupervised Learning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "1. Noisy vs Invalid Values\n",
    "    * Noisy implies the value is correct, just recorded incorrectly\n",
    "        * E.g., decimal place error (5.72 instead of 57.2), wrong categorical value used\n",
    "    * Invalid implies a noisy value that is not a valid value (for domain)\n",
    "        * E.g., 57.2X, misspelled categorical data, or value out of range (6 on a 5 point scale)\n",
    "    * Ways to deal with this:\n",
    "        * Look for duplicates (when there shouldn't be)\n",
    "        * Look for outliers\n",
    "        * Sort and print range of values\n",
    "    * The term \"noisy\" may also imply random error or random variance\n",
    "        * Various techniques to \"smooth out\" values\n",
    "        * E.g., using means of bins or regression\n",
    "2. Missing Values\n",
    "     * How should we deal with missing values?\n",
    "        * Discard instances: throw out any row with a missing value\n",
    "        * Replace with a new value:\n",
    "            * By hand\n",
    "            * Use a constant\n",
    "            * Use a central tendency measure (mean, median, most frequent, ...)\n",
    "        * Most \"probable\" value (e.g., regression, using a classifier)\n",
    "        * Replace either across data set, or based on similar instances\n",
    "            * E.g. average based on model year\n",
    "        \n",
    "## Summary Statistics\n",
    "Summary statistics give (initial) insights into a dataset, such as:\n",
    "1. Number of instances (how many rows)\n",
    "2. Min and max attribute values\n",
    "    * Q: Do these make sense for both categorical and continuous attributes?\n",
    "        * Ordinal, but not Nominal\n",
    "        * Much easier if numeric!\n",
    "        * Can only count number of each nominal value\n",
    "    * Q: What should be done with null (NA) values?\n",
    "        * Really, undefined / unknown\n",
    "        * In practice just ignore them\n",
    "3. Middle values of a distribution (aka “Central Tendency”)\n",
    "    * Mid value: `(max + min) / 2.0` \n",
    "        * AKA \"Midrange\"\n",
    "    * (Arithmetic) Mean $\\bar{x} = (x_1 + x_2 + ... + x_n) / n$\n",
    "        * AKA average\n",
    "        * Python: `sum(column) / float(len(column))`\n",
    "        * Q: Problems with the mean? ... sensitive to extremes (e.g., outliers)\n",
    "        * Q: Make sense for categorical and continuous?\n",
    "            * only Interval or Ratio (same widths)\n",
    "    * Median\n",
    "        * The middle value in a set of sorted values\n",
    "        * If even number of values, halfway between the two middles\n",
    "        * Better measure for skewed data\n",
    "        * Can be expensive for large data sets (sorting!)\n",
    "    * Mode\n",
    "        * Value(s) that occurs most frequently\n",
    "    * typically assume data is unimodal (one mode), e.g., normally distributed\n",
    "    * Q: How might we compute the mode in Python?\n",
    "4. Data Dispersion (Spread)\n",
    "    * Range (max - min)\n",
    "    * Quantiles: (Roughly) equal size partitions of data (if sorted from smallest to largest)\n",
    "        * \"2-quantiles\" is the data point that divides into two halves (AKA median)\n",
    "        * \"Quartiles\" is three data points that divide into four groups\n",
    "            * Used as part of box plots (more later)\n",
    "        * Interquartile range (IQR) is distance between 1st and 3rd quartiles\n",
    "        * \"Percentiles\" are 100-quantiles (100 groups)\n",
    "    * Variance and Standard Deviation\n",
    "        * Variance measures how spread out the data is (small implies data close to mean, large implies data spread out) $$\\frac{\\sum_{i=1}^{n}(x_i - \\bar{x})^2}{n}$$\n",
    "        * Standard Deviation is square root of variance\n",
    "            * Python: `numpy.std(vals)` \n",
    "                * ... more on numpy later\n",
    "        * For a normal (i.e., Gaussian) data distribution\n",
    "            * About 68% of values are within 1 standard deviation of mean\n",
    "            * About 95% of values are within 2 standard deviations\n",
    "            * About 99.7% of values are within 3 standard deviations"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
